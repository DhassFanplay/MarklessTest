<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>AR Floor Detection - Fixed Camera Flow</title>

  <!-- Load A-Frame -->
  <script src="https://aframe.io/releases/1.4.2/aframe.min.js "></script>

  <!-- Load OpenCV.js -->
  <script async src="https://docs.opencv.org/4.5.0/opencv.js "></script>

  <style>
    html, body {
      margin: 0;
      padding: 0;
      overflow: hidden;
      background: black;
      font-family: sans-serif;
    }

    #video, #canvas, #debugCanvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      object-fit: cover;
      z-index: 0;
      display: none; /* Hide until started */
    }

    #video { display: block; }

    .overlay {
      position: absolute;
      top: 20px;
      left: 50%;
      transform: translateX(-50%);
      text-align: center;
      z-index: 100;
    }

    .overlay button {
      display: block;
      margin: 10px auto;
      padding: 15px 30px;
      font-size: 16px;
      border: none;
      border-radius: 10px;
      color: white;
      background-color: rgba(0, 0, 0, 0.7);
      cursor: pointer;
    }

    #rescanButton, #placeCubeButton {
      display: none;
    }

    a-scene {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      pointer-events: none;
      z-index: 20;
    }

    #reticle {
      position: absolute;
      width: 30px;
      height: 30px;
      border: 2px solid red;
      border-radius: 50%;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      z-index: 30;
      pointer-events: none;
    }

    #statusText {
      position: absolute;
      bottom: 10px;
      left: 50%;
      transform: translateX(-50%);
      color: lime;
      font-size: 16px;
      z-index: 100;
      display: none;
    }
  </style>
</head>

<body>

<!-- Overlay UI -->
<div class="overlay" id="uiOverlay">
  <select id="cameraSelect">
    <option value="">Select Camera</option>
  </select>
  <button id="startButton" style="display: none;">Start Camera</button>
  <button id="rescanButton">Rescan Floor</button>
  <button id="placeCubeButton">Place Cube</button>
</div>

<div id="statusText">Looking for floor...</div>

<video id="video" autoplay playsinline></video>
<canvas id="canvas"></canvas>
<canvas id="debugCanvas"></canvas>
<div id="reticle"></div>

<!-- A-Frame Scene -->
<a-scene embedded arjs='trackingMethod: best;' vr-mode-ui="enabled: false">
  <!-- Lighting -->
  <a-entity light="type: ambient; intensity: 0.5;"></a-entity>
  <a-entity light="type: directional; color: #fff; intensity: 0.7;" position="-1 1 0"></a-entity>

  <!-- Red Cube (hidden initially) -->
  <a-box id="placedCube"
         color="red"
         depth="0.5"
         height="0.5"
         width="0.5"
         visible="false"
         position="0 0 -1">
  </a-box>

  <!-- Camera -->
  <a-entity id="camera" camera look-controls wasd-controls></a-entity>
</a-scene>

<script>
  const cameraSelect = document.getElementById('cameraSelect');
  const startButton = document.getElementById('startButton');
  const rescanButton = document.getElementById('rescanButton');
  const placeCubeButton = document.getElementById('placeCubeButton');
  const video = document.getElementById('video');
  const canvas = document.getElementById('canvas');
  const debugCanvas = document.getElementById('debugCanvas');
  const debugCtx = debugCanvas.getContext('2d');

  const ctx = canvas.getContext('2d');
  const cube = document.getElementById('placedCube');

  let isPlaced = false;

  // Wait for OpenCV to load
  const checkCv = setInterval(() => {
    if (typeof cv !== 'undefined') {
      clearInterval(checkCv);
      getCameras();
    }
  }, 100);

  // Get list of available cameras
  async function getCameras() {
    try {
      const devices = await navigator.mediaDevices.enumerateDevices();
      const videoDevices = devices.filter(device => device.kind === 'videoinput');

      if (videoDevices.length > 0) {
        cameraSelect.innerHTML = '<option value="">Select Camera</option>';

        videoDevices.forEach((device, index) => {
          const option = document.createElement('option');
          option.value = device.deviceId || '';
          option.text = `Camera ${index + 1} (${device.label || 'No label'})`;
          cameraSelect.appendChild(option);
        });

        cameraSelect.style.display = 'block';
        cameraSelect.addEventListener('change', () => {
          if (cameraSelect.value) {
            startButton.style.display = 'block';
          } else {
            startButton.style.display = 'none';
          }
        });
      } else {
        alert("No cameras found.");
      }
    } catch (err) {
      console.error("Error enumerating devices:", err);
      alert("Could not retrieve camera list.");
    }
  }

  // Start camera manually
  startButton.addEventListener('click', () => {
    const selectedCamera = cameraSelect.value;
    if (!selectedCamera) {
      alert("Please select a valid camera.");
      return;
    }

    const constraints = {
      video: {
        deviceId: { exact: selectedCamera }
      },
      audio: false
    };

    navigator.mediaDevices.getUserMedia(constraints)
      .then(stream => {
        video.srcObject = stream;
        video.onloadedmetadata = () => {
          video.play().catch(err => {
            console.error("Video play error:", err);
            alert("Could not play video.");
          });
        };
        startButton.style.display = 'none';
        rescanButton.style.display = 'block';
        placeCubeButton.style.display = 'block';
        requestAnimationFrame(processFrame);
      })
      .catch(async err => {
        console.error("Camera access failed:", err);
        alert("Failed to open selected camera. Trying default...");
        try {
          const fallbackStream = await navigator.mediaDevices.getUserMedia({ video: true });
          video.srcObject = fallbackStream;
          video.onloadedmetadata = () => video.play();
          startButton.style.display = 'none';
          rescanButton.style.display = 'block';
          placeCubeButton.style.display = 'block';
          requestAnimationFrame(processFrame);
        } catch (fallbackErr) {
          alert("Could not access any camera.");
          console.error("Fallback camera error:", fallbackErr);
        }
      });
  });

  // Reset cube placement and restart detection
  rescanButton.addEventListener('click', () => {
    cube.setAttribute('visible', false);
    isPlaced = false;
    statusText.textContent = "Looking for floor...";
    statusText.style.display = 'block';
    setTimeout(() => statusText.style.display = 'none', 2000);
  });

  // Place cube based on floor detection
  placeCubeButton.addEventListener('click', () => {
    const centerX = canvas.width / 2;
    const centerY = canvas.height / 2;

    let src = cv.imread(canvas);
    let gray = new cv.Mat();
    let edges = new cv.Mat();

    cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
    cv.Canny(gray, edges, 50, 150);

    let kernel = cv.getStructuringElement(cv.MORPH_RECT, new cv.Size(5, 5));
    cv.dilate(edges, edges, kernel, new cv.Point(-1, -1), 5);
    cv.erode(edges, edges, kernel, new cv.Point(-1, -1), 3);

    // Find contours
    let contours = new cv.MatVector();
    let hierarchy = new cv.Mat();
    cv.findContours(edges, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);

    let surfaceUnderCenter = false;

    for (let i = 0; i < contours.size(); ++i) {
      let cnt = contours.get(i);
      let rect = cv.boundingRect(cnt);

      if (
        centerX >= rect.x &&
        centerX <= rect.x + rect.width &&
        centerY >= rect.y &&
        centerY <= rect.y + rect.height
      ) {
        surfaceUnderCenter = true;
        break;
      }
    }

    // Cleanup
    src.delete(); gray.delete(); edges.delete(); contours.delete(); hierarchy.delete();

    if (surfaceUnderCenter && !isPlaced) {
      // Normalize to A-Frame coordinate system (-1 to 1)
      let xNorm = (centerX / canvas.width) * 2 - 1;
      let yNorm = (centerY / canvas.height) * 2 - 1;
      let zDepth = -1 - (yNorm * 0.5); // Estimate Z from Y

      cube.setAttribute('position', {
        x: xNorm,
        y: 0,
        z: zDepth
      });

      cube.setAttribute('visible', true);
      isPlaced = true;
    } else {
      alert("No surface under center. Try again.");
    }
  });

  // Main processing loop
  function processFrame() {
    if (video.videoWidth === 0 || video.videoHeight === 0 || !video.srcObject) {
      requestAnimationFrame(processFrame);
      return;
    }

    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    debugCanvas.width = canvas.width;
    debugCanvas.height = canvas.height;

    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
    debugCtx.clearRect(0, 0, debugCanvas.width, debugCanvas.height);

    if (!isPlaced) {
      try {
        let src = cv.imread(canvas);
        let gray = new cv.Mat();
        let edges = new cv.Mat();

        // Convert to grayscale
        cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);

        // Canny edge detection
        cv.Canny(gray, edges, 50, 150);

        // Morphological operations
        let kernel = cv.getStructuringElement(cv.MORPH_RECT, new cv.Size(5, 5));
        cv.dilate(edges, edges, kernel, new cv.Point(-1, -1), 5);
        cv.erode(edges, edges, kernel, new cv.Point(-1, -1), 3);

        // Find contours
        let contours = new cv.MatVector();
        let hierarchy = new cv.Mat();
        cv.findContours(edges, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);

        // Loop through contours
        for (let i = 0; i < contours.size(); ++i) {
          let cnt = contours.get(i);
          let area = cv.contourArea(cnt);

          if (area > 10000) {
            let rect = cv.boundingRect(cnt);
            drawDebugOverlay(rect.x, rect.y, rect.width, rect.height);
          }
        }

        // Cleanup
        src.delete(); gray.delete(); edges.delete(); contours.delete(); hierarchy.delete();
      } catch (err) {
        console.error("OpenCV Error:", err);
      }
    }

    requestAnimationFrame(processFrame);
  }

  // Draw semi-transparent overlay on floor-like surfaces
  function drawDebugOverlay(x, y, w, h) {
    debugCtx.fillStyle = "rgba(0, 255, 0, 0.3)";
    debugCtx.fillRect(x, y, w, h);
  }

  // Utility: Get longest line
  function getBestLine(lines) {
    if (lines.length === 0) return null;
    return lines.reduce((a, b) => {
      let lenA = Math.hypot(a.x2 - a.x1, a.y2 - a.y1);
      let lenB = Math.hypot(b.x2 - b.x1, b.y2 - b.y1);
      return lenA > lenB ? a : b;
    });
  }
</script>

</body>
</html>
